# geom_prompt_extractor/segmentation_processor.py
"""
Part 2: åˆ†å‰²å¤„ç†æ ¸å¿ƒ - æ€§èƒ½ä¼˜åŒ–ç‰ˆï¼ˆä¿®å¤ç‰ˆï¼‰
åŒ…å«ï¼šå‡ ä½•æ„ŸçŸ¥ç‚¹ç”Ÿæˆã€å¤šç­–ç•¥SAMåˆ†å‰²ã€è´¨é‡è¯„ä¼°
æ–°å¢ï¼šç»“æœç¼“å­˜ã€è®¡ç®—ä¼˜åŒ–ã€å†…å­˜ç®¡ç†ã€é»‘åº•å›¾åƒé¢„å¤„ç†
ä¿®å¤ï¼šæ·»åŠ é»‘åº•å›¾åƒå¤„ç†ã€æ”¹è¿›ç‚¹ç”Ÿæˆç­–ç•¥
"""

import torch
import numpy as np
import cv2
from typing import Tuple, List, Dict, Optional
from PIL import Image
import hashlib
import pickle
import time
from functools import lru_cache
import gc

# ä»é…ç½®æ¨¡å—å¯¼å…¥
from .config import ExtractionConfig, ObjectType

# æ£€æŸ¥ximgprocå¯ç”¨æ€§
try:
    import cv2.ximgproc

    HAS_XIMGPROC = True
except:
    HAS_XIMGPROC = False


class SegmentationProcessor:
    """åˆ†å‰²å¤„ç†å™¨ - å¤„ç†å‡ ä½•ç‚¹ç”Ÿæˆå’ŒSAMåˆ†å‰²ç­–ç•¥ï¼ˆä¿®å¤ç‰ˆï¼‰"""

    def __init__(self, sam_core, config: ExtractionConfig = None):
        """åˆå§‹åŒ–åˆ†å‰²å¤„ç†å™¨

        Args:
            sam_core: SAMCoreå®ä¾‹
            config: é…ç½®å¯¹è±¡
        """
        self.sam_core = sam_core
        self.config = config or ExtractionConfig()
        self.predictor = sam_core.get_predictor()

        # æ·»åŠ ç¼“å­˜å­—å…¸
        self._point_cache = {}  # å‡ ä½•ç‚¹ç¼“å­˜
        self._quality_cache = {}  # è´¨é‡è¯„ä¼°ç¼“å­˜
        self._segmentation_cache = {}  # åˆ†å‰²ç»“æœç¼“å­˜
        self._feature_cache = {}  # ç‰¹å¾æå–ç¼“å­˜

        # æ€§èƒ½ç»Ÿè®¡
        self.timing_stats = {
            'point_generation': [],
            'segmentation': [],
            'quality_eval': []
        }

    def clear_cache(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        self._point_cache.clear()
        self._quality_cache.clear()
        self._segmentation_cache.clear()
        self._feature_cache.clear()
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    def _get_mask_hash(self, mask: np.ndarray) -> str:
        """è®¡ç®—maskçš„hashå€¼ç”¨äºç¼“å­˜"""
        # é™é‡‡æ ·ä»¥åŠ é€Ÿhashè®¡ç®—
        if mask.size > 10000:
            mask_small = cv2.resize(mask.astype(np.uint8), (100, 100))
        else:
            mask_small = mask
        return hashlib.md5(mask_small.tobytes()).hexdigest()

    # ============= å›¾åƒé¢„å¤„ç†ï¼ˆæ–°å¢ï¼‰ =============

    def preprocess_image_for_segmentation(self, image: np.ndarray, object_type: ObjectType) -> np.ndarray:
        """é¢„å¤„ç†å›¾åƒä»¥æ”¹å–„åˆ†å‰²æ•ˆæœ - ç‰¹åˆ«å¤„ç†é»‘åº•å›¾åƒ"""
        # æ£€æµ‹æ˜¯å¦ä¸ºé»‘åº•äº®èŠ±çº¹
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        mean_brightness = np.mean(gray)

        # å¦‚æœæ˜¯æ·±è‰²èƒŒæ™¯ï¼ˆå¹³å‡äº®åº¦ä½äº100ï¼‰
        if mean_brightness < 100:
            # è®¡ç®—äº®è‰²å’Œæš—è‰²çš„æ¯”ä¾‹
            bright_ratio = np.sum(gray > 150) / gray.size
            dark_ratio = np.sum(gray < 50) / gray.size

            # å¦‚æœæš—è‰²å ä¸»å¯¼ä¸”æœ‰å°‘é‡äº®è‰²ï¼ˆå…¸å‹çš„é»‘åº•é‡‘/é“¶èŠ±ï¼‰
            if dark_ratio > 0.5 and bright_ratio < 0.3:
                print("  ğŸ”„ æ£€æµ‹åˆ°é»‘åº•äº®èŠ±çº¹ï¼Œæ‰§è¡Œå›¾åƒé¢„å¤„ç†...")

                # ç­–ç•¥1ï¼šå¢å¼ºå¯¹æ¯”åº¦
                # ä½¿ç”¨CLAHEå¢å¼ºå±€éƒ¨å¯¹æ¯”åº¦
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
                enhanced_gray = clahe.apply(gray)

                # ç­–ç•¥2ï¼šé¢œè‰²ç©ºé—´è½¬æ¢
                # å°†å¢å¼ºåçš„ç°åº¦å›¾è½¬å›RGB
                enhanced_rgb = cv2.cvtColor(enhanced_gray, cv2.COLOR_GRAY2RGB)

                # ç­–ç•¥3ï¼šé€‰æ‹©æ€§åè½¬
                # åªåœ¨æŸäº›æƒ…å†µä¸‹åè½¬å›¾åƒ
                if object_type == ObjectType.CARVING and bright_ratio < 0.1:
                    print("    ğŸ”„ åº”ç”¨é€‰æ‹©æ€§åè½¬...")
                    # åˆ›å»ºæ©ç ï¼šäº®è‰²éƒ¨åˆ†
                    _, bright_mask = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)

                    # åè½¬æ•´ä¸ªå›¾åƒ
                    inverted = cv2.bitwise_not(image)

                    # åªä¿ç•™äº®è‰²éƒ¨åˆ†çš„åè½¬
                    bright_mask_3ch = cv2.cvtColor(bright_mask, cv2.COLOR_GRAY2RGB)
                    result = np.where(bright_mask_3ch > 0, image, inverted)

                    return result
                else:
                    # è¿”å›å¢å¼ºåçš„å›¾åƒ
                    return enhanced_rgb

        return image

    # ============= å‡ ä½•æ„ŸçŸ¥ç‚¹ç”Ÿæˆï¼ˆä¼˜åŒ–ç‰ˆï¼‰ =============

    def generate_geometric_points(self, mask: np.ndarray,
                                  object_type: ObjectType,
                                  n_points: int = 120) -> np.ndarray:
        """V8å‡ ä½•æ„ŸçŸ¥ç‚¹ç”Ÿæˆç­–ç•¥ - ä¿®å¤ç‰ˆï¼ˆæ”¹è¿›é»‘åº•å¤„ç†ï¼‰"""
        start_time = time.time()

        if not np.any(mask):
            return np.array([])

        # æ£€æŸ¥ç¼“å­˜
        mask_hash = self._get_mask_hash(mask)
        cache_key = f"{mask_hash}_{object_type.value}_{n_points}"

        if cache_key in self._point_cache:
            print(f"  âš¡ ä½¿ç”¨ç¼“å­˜çš„å‡ ä½•ç‚¹")
            return self._point_cache[cache_key]

        mask_uint8 = mask.astype(np.uint8) * 255

        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœmaskä¸»è¦æ˜¯è¾¹ç¼˜ï¼ˆé»‘åº•å›¾åƒçš„å…¸å‹ç‰¹å¾ï¼‰
        edge_ratio = np.sum(mask) / mask.size
        if edge_ratio < 0.3:  # ç¨€ç–æ©ç 
            print(f"    ğŸ“ æ£€æµ‹åˆ°ç¨€ç–æ©ç  (å¯†åº¦: {edge_ratio:.2f})ï¼Œä½¿ç”¨è¾¹ç¼˜ä¼˜å…ˆç­–ç•¥")
            points = self._generate_edge_focused_points(mask_uint8, n_points)
            self._point_cache[cache_key] = points
            return points

        # è·å–ä¸»è¦è½®å»“
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            result = self._fallback_point_generation(mask, n_points)
            self._point_cache[cache_key] = result
            return result

        main_contour = max(contours, key=cv2.contourArea)
        geometric_points = []

        # å¹¶è¡Œæå–ç‰¹å¾ç‚¹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
        feature_extractors = [
            ('corners', self._extract_corner_points_fast),
            ('contour', self._extract_contour_points_fast),
            ('gradient', self._extract_gradient_points_fast),
            ('curvature', self._extract_curvature_points_fast),
        ]

        for name, extractor in feature_extractors:
            try:
                points = extractor(mask_uint8, main_contour, object_type)
                geometric_points.extend(points)
            except Exception as e:
                print(f"  âš ï¸ {name}æå–å¤±è´¥: {e}")

        # å¿«é€Ÿå»é‡
        if geometric_points:
            geometric_points = self._fast_remove_duplicates(geometric_points, mask.shape)
            geometric_points = geometric_points[:int(n_points * 0.8)]

        # è¡¥å……å†…éƒ¨é‡‡æ ·ç‚¹
        remaining_points = n_points - len(geometric_points)
        if remaining_points > 0:
            interior_points = self._generate_dense_interior_points_fast(mask, remaining_points)
            geometric_points.extend(interior_points)

        result = np.array(geometric_points[:n_points]) if geometric_points else np.array([])

        # ç¼“å­˜ç»“æœ
        self._point_cache[cache_key] = result

        # è®°å½•æ€§èƒ½
        elapsed = time.time() - start_time
        self.timing_stats['point_generation'].append(elapsed)

        print(f"  ğŸ¯ ç”ŸæˆV8å‡ ä½•æ„ŸçŸ¥ç‚¹: {len(result)}ä¸ª (è€—æ—¶: {elapsed:.3f}ç§’)")

        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self._point_cache) > 100:
            # åˆ é™¤æœ€è€çš„ä¸€åŠç¼“å­˜
            keys_to_remove = list(self._point_cache.keys())[:50]
            for key in keys_to_remove:
                del self._point_cache[key]

        return result

    def _generate_edge_focused_points(self, mask_uint8: np.ndarray, n_points: int) -> np.ndarray:
        """ä¸ºç¨€ç–æ©ç ç”Ÿæˆè¾¹ç¼˜èšç„¦çš„ç‚¹"""
        # æ‰¾åˆ°æ‰€æœ‰è¾¹ç¼˜ç‚¹
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        edge_points = []
        for contour in contours:
            # è·å–è½®å»“ç‚¹
            contour_points = contour.reshape(-1, 2)
            for point in contour_points:
                edge_points.append((point[1], point[0]))  # è½¬æ¢ä¸º(y, x)æ ¼å¼

        if len(edge_points) <= n_points:
            return np.array(edge_points)

        # å‡åŒ€é‡‡æ ·
        indices = np.linspace(0, len(edge_points) - 1, n_points, dtype=int)
        selected_points = [edge_points[i] for i in indices]

        return np.array(selected_points)

    def _extract_corner_points_fast(self, mask_uint8: np.ndarray,
                                    contour: np.ndarray,
                                    object_type: ObjectType) -> List[Tuple[int, int]]:
        """å¿«é€Ÿè§’ç‚¹æå–"""
        points = []

        # åªä½¿ç”¨ä¸€ä¸ªè´¨é‡çº§åˆ«
        quality = 0.001 if object_type == ObjectType.RELIEF else 0.005

        try:
            corners = cv2.goodFeaturesToTrack(
                mask_uint8,
                maxCorners=20,  # å‡å°‘è§’ç‚¹æ•°é‡
                qualityLevel=quality,
                minDistance=10,  # å¢åŠ æœ€å°è·ç¦»
                blockSize=5,
                useHarrisDetector=False,  # ä½¿ç”¨æ›´å¿«çš„æ–¹æ³•
                k=0.04
            )
            if corners is not None:
                corner_points = corners.reshape(-1, 2).astype(int)
                points = [(p[1], p[0]) for p in corner_points]
        except:
            pass

        return points

    def _extract_contour_points_fast(self, mask_uint8: np.ndarray,
                                     contour: np.ndarray,
                                     object_type: ObjectType) -> List[Tuple[int, int]]:
        """å¿«é€Ÿè½®å»“ç‚¹æå–"""
        contour_points = contour.reshape(-1, 2)
        n_samples = min(30, len(contour_points))  # å‡å°‘é‡‡æ ·æ•°

        if n_samples > 0:
            # ä½¿ç”¨å‡åŒ€é‡‡æ ·è€Œä¸æ˜¯éšæœº
            indices = np.linspace(0, len(contour_points) - 1, n_samples, dtype=int)
            return [(contour_points[idx][1], contour_points[idx][0]) for idx in indices]

        return []

    def _extract_gradient_points_fast(self, mask_uint8: np.ndarray,
                                      contour: np.ndarray,
                                      object_type: ObjectType) -> List[Tuple[int, int]]:
        """å¿«é€Ÿæ¢¯åº¦ç‚¹æå–"""
        # ä½¿ç”¨æ›´å°çš„æ ¸è¿›è¡Œæ¢¯åº¦è®¡ç®—
        grad_x = cv2.Sobel(mask_uint8, cv2.CV_16S, 1, 0, ksize=3)
        grad_y = cv2.Sobel(mask_uint8, cv2.CV_16S, 0, 1, ksize=3)

        # ä½¿ç”¨è¿‘ä¼¼è®¡ç®—ä»£æ›¿sqrt
        gradient_mag = np.abs(grad_x) + np.abs(grad_y)  # L1èŒƒæ•°ä»£æ›¿L2

        if np.any(gradient_mag > 0):
            # ä½¿ç”¨æ›´é«˜çš„ç™¾åˆ†ä½æ•°å‡å°‘ç‚¹æ•°
            threshold = np.percentile(gradient_mag[gradient_mag > 0], 80)
            gradient_points = np.argwhere(gradient_mag > threshold)

            if len(gradient_points) > 0:
                # é™åˆ¶ç‚¹æ•°å¹¶ä½¿ç”¨æ­¥è¿›é‡‡æ ·
                step = max(1, len(gradient_points) // 15)
                selected = gradient_points[::step][:15]
                return [(p[0], p[1]) for p in selected]

        return []

    def _extract_curvature_points_fast(self, mask_uint8: np.ndarray,
                                       contour: np.ndarray,
                                       object_type: ObjectType) -> List[Tuple[int, int]]:
        """å¿«é€Ÿæ›²ç‡ç‚¹æå– - ç®€åŒ–ç‰ˆ"""
        if len(contour) < 10:
            return []

        points = contour.reshape(-1, 2)
        n_samples = min(10, len(points) // 5)  # å‡å°‘é‡‡æ ·

        # åªè®¡ç®—éƒ¨åˆ†ç‚¹çš„æ›²ç‡
        step = max(1, len(points) // (n_samples * 2))
        curvature_points = []

        for i in range(0, len(points), step):
            if len(curvature_points) >= n_samples:
                break
            x, y = points[i]
            curvature_points.append((y, x))

        return curvature_points

    def _fast_remove_duplicates(self, points: List[Tuple[int, int]],
                                shape: Tuple[int, int]) -> List[Tuple[int, int]]:
        """å¿«é€Ÿå»é‡ - ä½¿ç”¨ç½‘æ ¼åŒ–æ–¹æ³•"""
        if not points:
            return points

        # åˆ›å»ºç½‘æ ¼æ¥å¿«é€Ÿæ£€æŸ¥é‡å¤
        grid_size = 5  # ç½‘æ ¼å•å…ƒå¤§å°
        h, w = shape
        grid = {}

        unique_points = []
        for y, x in points:
            # ç¡®ä¿ç‚¹åœ¨è¾¹ç•Œå†…
            if not (0 <= y < h and 0 <= x < w):
                continue

            # è®¡ç®—ç½‘æ ¼åæ ‡
            grid_y, grid_x = y // grid_size, x // grid_size
            grid_key = (grid_y, grid_x)

            # æ£€æŸ¥è¯¥ç½‘æ ¼å•å…ƒæ˜¯å¦å·²æœ‰ç‚¹
            if grid_key not in grid:
                grid[grid_key] = True
                unique_points.append((y, x))

        return unique_points

    def _generate_dense_interior_points_fast(self, mask: np.ndarray,
                                             n_points: int) -> List[Tuple[int, int]]:
        """å¿«é€Ÿç”Ÿæˆå†…éƒ¨é‡‡æ ·ç‚¹"""
        # ä½¿ç”¨æ›´å°çš„è·ç¦»å˜æ¢åŠ é€Ÿ
        mask_small = cv2.resize(mask.astype(np.uint8), None, fx=0.5, fy=0.5)
        dist_small = cv2.distanceTransform(mask_small, cv2.DIST_L2, 3)

        # æ‰¾åˆ°å†…éƒ¨ç‚¹
        interior_mask = dist_small > 1
        interior_coords = np.argwhere(interior_mask)

        if len(interior_coords) > 0:
            # éšæœºé‡‡æ ·å¹¶ç¼©æ”¾å›åŸå§‹å¤§å°
            n_samples = min(n_points, len(interior_coords))
            indices = np.random.choice(len(interior_coords), n_samples, replace=False)
            points = [(int(interior_coords[i][0] * 2),
                       int(interior_coords[i][1] * 2)) for i in indices]

            # ç¡®ä¿ç‚¹åœ¨åŸå§‹maskå†…
            h, w = mask.shape
            valid_points = []
            for y, x in points:
                if 0 <= y < h and 0 <= x < w and mask[y, x]:
                    valid_points.append((y, x))

            return valid_points[:n_points]

        return []

    def _fallback_point_generation(self, mask: np.ndarray, n_points: int) -> np.ndarray:
        """é™çº§ç‚¹ç”Ÿæˆç­–ç•¥ - ä¼˜åŒ–ç‰ˆ"""
        positive_coords = np.argwhere(mask)
        if len(positive_coords) <= n_points:
            return positive_coords

        # ä½¿ç”¨ç³»ç»Ÿé‡‡æ ·è€Œä¸æ˜¯éšæœº
        step = max(1, len(positive_coords) // n_points)
        return positive_coords[::step][:n_points]

    # ============= å¤šç­–ç•¥SAMåˆ†å‰²ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ =============

    def multi_prompt_sam_segmentation(self, image: Image.Image,
                                      content_box: Tuple[int, int, int, int],
                                      initial_mask: np.ndarray,
                                      geometric_points: np.ndarray,
                                      object_type: ObjectType) -> Tuple[torch.Tensor, float, str]:
        """V8å¤šæç¤ºç­–ç•¥SAMåˆ†å‰² - ä¿®å¤ç‰ˆï¼ˆæ·»åŠ é¢„å¤„ç†ï¼‰"""
        start_time = time.time()

        # ç”Ÿæˆç¼“å­˜é”®
        img_array = np.array(image)

        # æ–°å¢ï¼šé¢„å¤„ç†å›¾åƒ
        processed_img = self.preprocess_image_for_segmentation(img_array, object_type)

        img_hash = hashlib.md5(
            cv2.resize(processed_img, (50, 50)).tobytes()
        ).hexdigest()

        cache_key = f"{img_hash}_{content_box}_{object_type.value}"

        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self._segmentation_cache:
            print(f"  âš¡ ä½¿ç”¨ç¼“å­˜çš„åˆ†å‰²ç»“æœ")
            cached = self._segmentation_cache[cache_key]
            return cached['mask'], cached['score'], cached['method']

        # è®¾ç½®å›¾åƒï¼ˆä½¿ç”¨å¤„ç†åçš„å›¾åƒï¼‰
        self.predictor.set_image(processed_img)

        results = []

        # ç­–ç•¥1: æ¡†æç¤º
        if self.config.enable_multi_prompt:
            try:
                x, y, w, h = content_box
                margin = 5
                box_array = np.array([x + margin, y + margin,
                                      x + w - margin, y + h - margin])

                with torch.no_grad():
                    masks, scores, _ = self.predictor.predict(
                        box=box_array,
                        multimask_output=True
                    )

                best_idx = np.argmax(scores)
                results.append(('box', masks[best_idx], scores[best_idx]))
                print(f"  ğŸ“¦ æ¡†æç¤ºåˆ†æ•°: {scores[best_idx]:.3f}")
            except Exception as e:
                print(f"  âŒ æ¡†æç¤ºå¤±è´¥: {e}")

        # ç­–ç•¥2: å‡ ä½•ç‚¹æç¤ºï¼ˆå¦‚æœæœ‰ç‚¹ï¼‰
        if len(geometric_points) > 0:
            try:
                # é™åˆ¶ç‚¹æ•°ä»¥åŠ é€Ÿ
                max_points = 50
                if len(geometric_points) > max_points:
                    # éšæœºé€‰æ‹©å­é›†
                    indices = np.random.choice(len(geometric_points),
                                               max_points, replace=False)
                    selected_points = geometric_points[indices]
                else:
                    selected_points = geometric_points

                points = np.array([[p[1], p[0]] for p in selected_points])
                labels = np.ones(len(points))

                # ç®€åŒ–è´Ÿæ ·æœ¬ç‚¹ç”Ÿæˆ
                negative_points = self._generate_negative_points_fast(
                    processed_img.shape[:2], content_box, initial_mask
                )

                if len(negative_points) > 0:
                    neg_points = np.array([[p[1], p[0]] for p in negative_points])
                    points = np.vstack([points, neg_points])
                    labels = np.hstack([labels, np.zeros(len(neg_points))])

                with torch.no_grad():
                    masks, scores, _ = self.predictor.predict(
                        point_coords=points,
                        point_labels=labels,
                        multimask_output=True
                    )

                best_idx = np.argmax(scores)
                results.append(('geometric_points', masks[best_idx], scores[best_idx]))
                print(f"  ğŸ¯ å‡ ä½•ç‚¹æç¤ºåˆ†æ•°: {scores[best_idx]:.3f}")
            except Exception as e:
                print(f"  âŒ å‡ ä½•ç‚¹æç¤ºå¤±è´¥: {e}")

        # ç­–ç•¥3: æ©ç å¼•å¯¼ï¼ˆä»…å½“åˆå§‹æ©ç è´¨é‡é«˜æ—¶ï¼‰
        if initial_mask is not None and self.config.enable_hierarchical:
            initial_quality = self._quick_quality_check(initial_mask)
            if initial_quality > 0.65:
                try:
                    h, w = processed_img.shape[:2]
                    kernel = np.ones((3, 3), np.uint8)
                    initial_mask_eroded = cv2.erode(
                        initial_mask.astype(np.uint8), kernel, iterations=1
                    )

                    mask_input = cv2.resize(
                        initial_mask_eroded.astype(np.float32), (w, h)
                    )
                    mask_input_resized = cv2.resize(
                        mask_input, (256, 256), interpolation=cv2.INTER_NEAREST
                    )

                    mask_input_tensor = torch.as_tensor(
                        mask_input_resized, device=self.sam_core.device
                    ).unsqueeze(0)

                    with torch.no_grad():
                        masks, scores, _ = self.predictor.predict(
                            mask_input=mask_input_tensor,
                            multimask_output=True
                        )

                    best_idx = np.argmax(scores)
                    results.append(('mask_guided', masks[best_idx], scores[best_idx]))
                    print(f"  ğŸ­ æ©ç å¼•å¯¼åˆ†æ•°: {scores[best_idx]:.3f}")
                except Exception as e:
                    print(f"  âŒ æ©ç å¼•å¯¼å¤±è´¥: {e}")

        # é€‰æ‹©æœ€ä½³ç»“æœ
        if results:
            best_result = None
            best_composite_score = -1

            for method, mask, score in results:
                # ä½¿ç”¨å¿«é€Ÿè´¨é‡è¯„ä¼°
                geometric_quality = self._quick_quality_check(mask)
                composite_score = score * 0.6 + geometric_quality * 0.4

                if composite_score > best_composite_score:
                    best_composite_score = composite_score
                    best_result = (method, mask, score)

            if best_result:
                method, mask, score = best_result
                print(f"  âœ… é€‰æ‹©æœ€ä½³ç­–ç•¥: {method}")

                # ç¼“å­˜ç»“æœ
                self._segmentation_cache[cache_key] = {
                    'mask': torch.from_numpy(mask),
                    'score': score,
                    'method': method
                }

                # é™åˆ¶ç¼“å­˜å¤§å°
                if len(self._segmentation_cache) > 50:
                    keys_to_remove = list(self._segmentation_cache.keys())[:25]
                    for key in keys_to_remove:
                        del self._segmentation_cache[key]

                # è®°å½•æ€§èƒ½
                elapsed = time.time() - start_time
                self.timing_stats['segmentation'].append(elapsed)

                return torch.from_numpy(mask), score, method

        # é™çº§å¤„ç†
        print("  ğŸ”„ é™çº§ä½¿ç”¨åˆå§‹æ©ç ")
        full_mask = np.zeros(processed_img.shape[:2], dtype=bool)
        x, y, w, h = content_box
        if initial_mask is not None and initial_mask.shape == (h, w):
            full_mask[y:y + h, x:x + w] = initial_mask

        return torch.from_numpy(full_mask), 0.5, 'fallback'

    def _generate_negative_points_fast(self, shape: Tuple[int, int],
                                       content_box: Tuple[int, int, int, int],
                                       mask: np.ndarray) -> List[Tuple[int, int]]:
        """å¿«é€Ÿç”Ÿæˆè´Ÿæ ·æœ¬ç‚¹"""
        h, w = shape
        x, y, bw, bh = content_box

        # åªç”Ÿæˆå°‘é‡å…³é”®è´Ÿæ ·æœ¬ç‚¹
        negative_points = []

        # å››ä¸ªè§’ç‚¹
        margin = 10
        corner_points = [
            (y - margin, x - margin),
            (y - margin, x + bw + margin),
            (y + bh + margin, x - margin),
            (y + bh + margin, x + bw + margin)
        ]

        for py, px in corner_points:
            if 0 <= py < h and 0 <= px < w:
                negative_points.append((py, px))

        # å››ä¸ªè¾¹ç•Œä¸­ç‚¹
        edge_points = [
            (y - margin, x + bw // 2),
            (y + bh + margin, x + bw // 2),
            (y + bh // 2, x - margin),
            (y + bh // 2, x + bw + margin)
        ]

        for py, px in edge_points:
            if 0 <= py < h and 0 <= px < w:
                negative_points.append((py, px))

        return negative_points[:10]  # æœ€å¤š10ä¸ªè´Ÿæ ·æœ¬ç‚¹

    # ============= è´¨é‡è¯„ä¼°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ =============

    def evaluate_mask_quality(self, mask: np.ndarray,
                              object_type: ObjectType) -> float:
        """è¯„ä¼°æ©ç è´¨é‡ - å¸¦ç¼“å­˜"""
        start_time = time.time()

        if not np.any(mask):
            return 0.0

        # æ£€æŸ¥ç¼“å­˜
        mask_hash = self._get_mask_hash(mask)
        cache_key = f"{mask_hash}_{object_type.value}"

        if cache_key in self._quality_cache:
            return self._quality_cache[cache_key]

        # æ‰§è¡Œè´¨é‡è¯„ä¼°
        quality = self._compute_quality(mask, object_type)

        # ç¼“å­˜ç»“æœ
        self._quality_cache[cache_key] = quality

        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self._quality_cache) > 100:
            keys_to_remove = list(self._quality_cache.keys())[:50]
            for key in keys_to_remove:
                del self._quality_cache[key]

        # è®°å½•æ€§èƒ½
        elapsed = time.time() - start_time
        self.timing_stats['quality_eval'].append(elapsed)

        return quality

    def _quick_quality_check(self, mask: np.ndarray) -> float:
        """å¿«é€Ÿè´¨é‡æ£€æŸ¥ - ç”¨äºä¸­é—´æ­¥éª¤"""
        if not np.any(mask):
            return 0.0

        mask_uint8 = mask.astype(np.uint8)

        # åªæ£€æŸ¥è¿é€šæ€§
        num_labels, _, stats, _ = cv2.connectedComponentsWithStats(mask_uint8)

        if num_labels > 1:
            max_area = stats[1:, -1].max()
            total_area = mask.sum()
            if total_area > 0:
                return max_area / total_area

        return 0.8  # å•ä¸€è¿é€šç»„ä»¶

    def _compute_quality(self, mask: np.ndarray,
                         object_type: ObjectType) -> float:
        """è®¡ç®—å®Œæ•´è´¨é‡åˆ†æ•°"""
        mask_uint8 = mask.astype(np.uint8)

        # è¿é€šæ€§
        num_labels, _, stats, _ = cv2.connectedComponentsWithStats(mask_uint8)
        connectivity_score = 0
        if num_labels > 1:
            max_size = stats[1:, -1].max()
            connectivity_score = max_size / mask.sum() if mask.sum() > 0 else 0
        else:
            connectivity_score = 1.0

        # ç´§å‡‘æ€§ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL,
                                       cv2.CHAIN_APPROX_SIMPLE)
        compactness_score = 0.5  # é»˜è®¤å€¼

        if contours:
            main_contour = max(contours, key=cv2.contourArea)
            # ä½¿ç”¨è¾¹ç•Œæ¡†è¿‘ä¼¼ä»£æ›¿å‡¸åŒ…è®¡ç®—
            x, y, w, h = cv2.boundingRect(main_contour)
            bbox_area = w * h
            contour_area = cv2.contourArea(main_contour)
            if bbox_area > 0:
                compactness_score = contour_area / bbox_area

        base_score = connectivity_score * 0.6 + compactness_score * 0.4

        if self.config.use_geometric_quality and object_type in [ObjectType.CARVING, ObjectType.RELIEF]:
            # ç®€åŒ–çš„å¯¹ç§°æ€§æ£€æŸ¥
            symmetry_score = self._quick_symmetry_score(mask_uint8)
            final_score = base_score * 0.7 + symmetry_score * 0.3
        else:
            final_score = base_score

        return min(final_score, 1.0)

    def _quick_symmetry_score(self, mask: np.ndarray) -> float:
        """å¿«é€Ÿå¯¹ç§°æ€§è¯„åˆ†"""
        h, w = mask.shape

        # åªæ£€æŸ¥å‚ç›´å¯¹ç§°
        if w > 1:
            left_half = mask[:, :w // 2]
            right_half = np.fliplr(mask[:, w - (w // 2):])
            min_w = min(left_half.shape[1], right_half.shape[1])

            if min_w > 0:
                # é™é‡‡æ ·ä»¥åŠ é€Ÿæ¯”è¾ƒ
                if h > 50:
                    left_small = cv2.resize(left_half[:, :min_w], (20, 20))
                    right_small = cv2.resize(right_half[:, :min_w], (20, 20))
                    return np.mean(left_small == right_small)
                else:
                    return np.mean(left_half[:, :min_w] == right_half[:, :min_w])

        return 0.5

    def print_performance_stats(self):
        """æ‰“å°æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        for name, times in self.timing_stats.items():
            if times:
                avg_time = np.mean(times)
                max_time = np.max(times)
                min_time = np.min(times)
                print(f"  {name}:")
                print(f"    å¹³å‡: {avg_time:.3f}ç§’")
                print(f"    æœ€å¿«: {min_time:.3f}ç§’")
                print(f"    æœ€æ…¢: {max_time:.3f}ç§’")

        print(f"\nğŸ’¾ ç¼“å­˜ä½¿ç”¨:")
        print(f"  å‡ ä½•ç‚¹ç¼“å­˜: {len(self._point_cache)}é¡¹")
        print(f"  åˆ†å‰²ç¼“å­˜: {len(self._segmentation_cache)}é¡¹")
        print(f"  è´¨é‡ç¼“å­˜: {len(self._quality_cache)}é¡¹")